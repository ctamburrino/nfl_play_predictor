{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "514ca125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "import catboost\n",
    "catboost.__version__\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0d677874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play_id</th>\n",
       "      <th>posteam</th>\n",
       "      <th>defteam</th>\n",
       "      <th>posteam_type</th>\n",
       "      <th>yardline_100</th>\n",
       "      <th>qtr</th>\n",
       "      <th>down</th>\n",
       "      <th>ydstogo</th>\n",
       "      <th>goal_to_go</th>\n",
       "      <th>score_differential</th>\n",
       "      <th>...</th>\n",
       "      <th>drive</th>\n",
       "      <th>posteam_timeouts_remaining</th>\n",
       "      <th>defteam_timeouts_remaining</th>\n",
       "      <th>shotgun</th>\n",
       "      <th>no_huddle</th>\n",
       "      <th>quarter_seconds_remaining</th>\n",
       "      <th>half_seconds_remaining</th>\n",
       "      <th>game_seconds_remaining</th>\n",
       "      <th>side_of_field</th>\n",
       "      <th>play_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>PIT</td>\n",
       "      <td>TEN</td>\n",
       "      <td>home</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>1793.0</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>PIT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>PIT</td>\n",
       "      <td>TEN</td>\n",
       "      <td>home</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>3556.0</td>\n",
       "      <td>PIT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113</td>\n",
       "      <td>PIT</td>\n",
       "      <td>TEN</td>\n",
       "      <td>home</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>1715.0</td>\n",
       "      <td>3515.0</td>\n",
       "      <td>PIT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162</td>\n",
       "      <td>TEN</td>\n",
       "      <td>PIT</td>\n",
       "      <td>away</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>3496.0</td>\n",
       "      <td>TEN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183</td>\n",
       "      <td>TEN</td>\n",
       "      <td>PIT</td>\n",
       "      <td>away</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>TEN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   play_id posteam defteam posteam_type  yardline_100  qtr  down  ydstogo  \\\n",
       "0       68     PIT     TEN         home          58.0    1     1       10   \n",
       "1       92     PIT     TEN         home          53.0    1     2        5   \n",
       "2      113     PIT     TEN         home          56.0    1     3        8   \n",
       "3      162     TEN     PIT         away          98.0    1     1       10   \n",
       "4      183     TEN     PIT         away          98.0    1     2       10   \n",
       "\n",
       "   goal_to_go  score_differential  ... drive  posteam_timeouts_remaining  \\\n",
       "0           0                 0.0  ...     1                           3   \n",
       "1           0                 0.0  ...     1                           3   \n",
       "2           0                 0.0  ...     1                           3   \n",
       "3           0                 0.0  ...     2                           3   \n",
       "4           0                 0.0  ...     2                           3   \n",
       "\n",
       "   defteam_timeouts_remaining  shotgun  no_huddle  quarter_seconds_remaining  \\\n",
       "0                           3        0          0                      893.0   \n",
       "1                           3        0          0                      856.0   \n",
       "2                           3        1          0                      815.0   \n",
       "3                           3        0          0                      796.0   \n",
       "4                           3        0          0                      760.0   \n",
       "\n",
       "   half_seconds_remaining  game_seconds_remaining  side_of_field play_type  \n",
       "0                  1793.0                  3593.0            PIT         1  \n",
       "1                  1756.0                  3556.0            PIT         0  \n",
       "2                  1715.0                  3515.0            PIT         1  \n",
       "3                  1696.0                  3496.0            TEN         0  \n",
       "4                  1660.0                  3460.0            TEN         1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/nfl_encoded_v2.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ff3e40",
   "metadata": {},
   "source": [
    "Identify categorical and numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "671ea0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: ['posteam', 'defteam', 'posteam_type', 'game_half', 'side_of_field']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posteam</th>\n",
       "      <th>defteam</th>\n",
       "      <th>posteam_type</th>\n",
       "      <th>game_half</th>\n",
       "      <th>side_of_field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIT</td>\n",
       "      <td>TEN</td>\n",
       "      <td>home</td>\n",
       "      <td>Half1</td>\n",
       "      <td>PIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIT</td>\n",
       "      <td>TEN</td>\n",
       "      <td>home</td>\n",
       "      <td>Half1</td>\n",
       "      <td>PIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIT</td>\n",
       "      <td>TEN</td>\n",
       "      <td>home</td>\n",
       "      <td>Half1</td>\n",
       "      <td>PIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEN</td>\n",
       "      <td>PIT</td>\n",
       "      <td>away</td>\n",
       "      <td>Half1</td>\n",
       "      <td>TEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEN</td>\n",
       "      <td>PIT</td>\n",
       "      <td>away</td>\n",
       "      <td>Half1</td>\n",
       "      <td>TEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  posteam defteam posteam_type game_half side_of_field\n",
       "0     PIT     TEN         home     Half1           PIT\n",
       "1     PIT     TEN         home     Half1           PIT\n",
       "2     PIT     TEN         home     Half1           PIT\n",
       "3     TEN     PIT         away     Half1           TEN\n",
       "4     TEN     PIT         away     Half1           TEN"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify categorical vs numeric features\n",
    "categorical_features = [\"posteam\", \"defteam\", \"posteam_type\",\"game_half\", \"side_of_field\"]\n",
    "numeric_features = X.select_dtypes(include=[\"float32\", \"float64\"]).columns.tolist()\n",
    "\n",
    "# REMOVE categorical features that are actually numeric\n",
    "numeric_features = [col for col in numeric_features if col not in categorical_features]\n",
    "\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "df[categorical_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b49b6b",
   "metadata": {},
   "source": [
    "Label encode all categorical columns for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d4459963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "df_encoded = df.copy()\n",
    "\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee56f7c6",
   "metadata": {},
   "source": [
    "Split data for PyTorch using the encoded dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "70c22964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (223067, 19)\n",
      "Validation shape: (47800, 19)\n",
      "Testing shape: (47801, 19)\n"
     ]
    }
   ],
   "source": [
    "X = df_encoded.drop(columns=[\"play_type\", \"play_id\"], errors=\"ignore\")\n",
    "y = df_encoded[\"play_type\"]\n",
    "\n",
    "categorical_features = [\"posteam\", \"defteam\", \"posteam_type\", \"game_half\", \"side_of_field\"]\n",
    "\n",
    "numeric_features = [\n",
    "    col for col in df_encoded.columns\n",
    "    if col not in categorical_features + [\"play_type\", \"play_id\"]\n",
    "]\n",
    "\n",
    "cat_cardinalities = [df_encoded[col].nunique() for col in categorical_features]\n",
    "\n",
    "#First split: train (70%) and temp (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "#Second split: validation (15%) and test (15%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Training shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n",
    "print(\"Testing shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf808f2d",
   "metadata": {},
   "source": [
    "Train CatBoost using the ORIGINAL dataframe (not encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "4ccd6b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cb = df.drop(columns=[\"play_type\", \"play_id\"], errors=\"ignore\")\n",
    "y_cb = df[\"play_type\"]\n",
    "\n",
    "X_train_cb, X_temp_cb, y_train_cb, y_temp_cb = train_test_split(\n",
    "    X_cb, y_cb, test_size=0.3, random_state=42, stratify=y_cb\n",
    ")\n",
    "\n",
    "X_val_cb, X_test_cb, y_val_cb, y_test_cb = train_test_split(\n",
    "    X_temp_cb, y_temp_cb, test_size=0.5, random_state=42, stratify=y_temp_cb\n",
    ")\n",
    "\n",
    "cat_features_cb = X_cb.select_dtypes(\"object\").columns.tolist()\n",
    "cat_feature_indices_cb = [X_cb.columns.get_loc(col) for col in cat_features_cb]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "e2dca19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: ['posteam', 'defteam', 'posteam_type', 'game_half', 'side_of_field']\n",
      "Categorical feature indices: [0, 1, 2, 9, 18]\n"
     ]
    }
   ],
   "source": [
    "cat_feature_indices = [X.columns.get_loc(col) for col in categorical_features]\n",
    "\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"Categorical feature indices:\", cat_feature_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f0ae1b",
   "metadata": {},
   "source": [
    "K fold cross validation and OOF predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "78d57035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Fold 2/5\n",
      "Fold 3/5\n",
      "Fold 4/5\n",
      "Fold 5/5\n",
      "0:\ttest: 0.7760523\tbest: 0.7760523 (0)\ttotal: 267ms\tremaining: 5m 19s\n",
      "100:\ttest: 0.8032336\tbest: 0.8032336 (100)\ttotal: 22.7s\tremaining: 4m 7s\n",
      "200:\ttest: 0.8063418\tbest: 0.8063418 (200)\ttotal: 44.8s\tremaining: 3m 42s\n",
      "300:\ttest: 0.8073007\tbest: 0.8073007 (300)\ttotal: 1m 6s\tremaining: 3m 17s\n",
      "400:\ttest: 0.8077827\tbest: 0.8077827 (400)\ttotal: 1m 25s\tremaining: 2m 49s\n",
      "500:\ttest: 0.8080014\tbest: 0.8080014 (500)\ttotal: 1m 43s\tremaining: 2m 24s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8080167417\n",
      "bestIteration = 504\n",
      "\n",
      "Shrink model to first 505 iterations.\n"
     ]
    }
   ],
   "source": [
    "# Set up K-Fold cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# Initialize array for storing OOF predictions\n",
    "oof_proba = np.zeros(len(y_train))\n",
    "\n",
    "# Generate OOF predictions\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_cb), 1):\n",
    "    print(f\"Fold {fold}/{n_splits}\")\n",
    "\n",
    "    X_tr, X_val_fold = X_train_cb.iloc[train_idx], X_train_cb.iloc[val_idx]\n",
    "    y_tr, y_val_fold = y_train_cb.iloc[train_idx], y_train_cb.iloc[val_idx]\n",
    "\n",
    "    fold_model = CatBoostClassifier(\n",
    "        loss_function='Logloss',\n",
    "        eval_metric='AUC',\n",
    "        depth=6,\n",
    "        learning_rate=0.1,\n",
    "        iterations=1200,\n",
    "        od_type='Iter',\n",
    "        od_wait=50,\n",
    "        random_seed=RANDOM_SEED + fold,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    fold_model.fit(\n",
    "        X_tr, y_tr,\n",
    "        cat_features=cat_feature_indices_cb,\n",
    "        eval_set=(X_val_fold, y_val_fold),\n",
    "        use_best_model=True,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Store fold predictions for OOF\n",
    "    oof_proba[val_idx] = fold_model.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "cat_model_full = CatBoostClassifier(\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    depth=6,\n",
    "    learning_rate=0.1,\n",
    "    iterations=1200,\n",
    "    od_type='Iter',\n",
    "    od_wait=50,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "cat_model_full.fit(\n",
    "    X_train_cb, y_train_cb,\n",
    "    cat_features=cat_feature_indices_cb,\n",
    "    eval_set=(X_val_cb, y_val_cb),\n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "# Get validation and test predictions\n",
    "val_proba = cat_model_full.predict_proba(X_val_cb)[:, 1]\n",
    "test_proba = cat_model_full.predict_proba(X_test_cb)[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "403a80f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7760523\tbest: 0.7760523 (0)\ttotal: 173ms\tremaining: 3m 27s\n",
      "100:\ttest: 0.8032336\tbest: 0.8032336 (100)\ttotal: 16.2s\tremaining: 2m 56s\n",
      "200:\ttest: 0.8063418\tbest: 0.8063418 (200)\ttotal: 35.6s\tremaining: 2m 56s\n",
      "300:\ttest: 0.8073007\tbest: 0.8073007 (300)\ttotal: 54.5s\tremaining: 2m 42s\n",
      "400:\ttest: 0.8077827\tbest: 0.8077827 (400)\ttotal: 1m 15s\tremaining: 2m 30s\n",
      "500:\ttest: 0.8080014\tbest: 0.8080014 (500)\ttotal: 1m 36s\tremaining: 2m 14s\n",
      "600:\ttest: 0.8080895\tbest: 0.8081097 (594)\ttotal: 1m 58s\tremaining: 1m 57s\n",
      "700:\ttest: 0.8081632\tbest: 0.8081632 (700)\ttotal: 2m 22s\tremaining: 1m 41s\n",
      "800:\ttest: 0.8082217\tbest: 0.8082572 (789)\ttotal: 2m 47s\tremaining: 1m 23s\n",
      "900:\ttest: 0.8082866\tbest: 0.8082970 (896)\ttotal: 3m 10s\tremaining: 1m 3s\n",
      "1000:\ttest: 0.8084354\tbest: 0.8084482 (992)\ttotal: 3m 31s\tremaining: 42s\n",
      "Stopped by overfitting detector  (80 iterations wait)\n",
      "\n",
      "bestTest = 0.8084601836\n",
      "bestIteration = 1006\n",
      "\n",
      "Shrink model to first 1007 iterations.\n"
     ]
    }
   ],
   "source": [
    "cat_model_full = CatBoostClassifier(\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    depth=6,\n",
    "    learning_rate=0.1,\n",
    "    iterations=1200,\n",
    "    od_type='Iter',\n",
    "    od_wait=80,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "cat_model_full.fit(\n",
    "    X_train_cb, y_train_cb,\n",
    "    cat_features=cat_feature_indices_cb,\n",
    "    eval_set=(X_val_cb, y_val_cb),\n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "# Get validation and test predictions\n",
    "val_proba = cat_model_full.predict_proba(X_val_cb)[:, 1]\n",
    "test_proba = cat_model_full.predict_proba(X_test_cb)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d32cb44",
   "metadata": {},
   "source": [
    "Extract CatBoost Leaf Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "f0610429",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_leaves = cat_model_full.calc_leaf_indexes(catboost.Pool(X_train_cb, cat_features=cat_feature_indices_cb))\n",
    "val_leaves = cat_model_full.calc_leaf_indexes(catboost.Pool(X_val_cb, cat_features=cat_feature_indices_cb))\n",
    "test_leaves = cat_model_full.calc_leaf_indexes(catboost.Pool(X_test_cb, cat_features=cat_feature_indices_cb))\n",
    "\n",
    "n_trees = train_leaves.shape[1]\n",
    "n_leaf_values = max(train_leaves.max(), val_leaves.max(), test_leaves.max()) + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172283f3",
   "metadata": {},
   "source": [
    "Convert leaves into embeddings in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "226771a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class PlayDataset(Dataset):\n",
    "    def __init__(self, X_num, X_cat, leaf_idx, y):\n",
    "        self.X_num = torch.tensor(X_num.values.astype(np.float32))\n",
    "        self.X_cat = torch.tensor(X_cat.values.astype(np.int64))\n",
    "        self.leaf_idx = torch.tensor(leaf_idx.astype(np.int64))\n",
    "        self.y = torch.tensor(y.values.astype(np.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.X_num[idx],\n",
    "            self.X_cat[idx],\n",
    "            self.leaf_idx[idx],\n",
    "            self.y[idx]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "2b0275af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num_train = X_train[numeric_features]\n",
    "X_cat_train = X_train[categorical_features]\n",
    "\n",
    "X_num_val = X_val[numeric_features]\n",
    "X_cat_val = X_val[categorical_features]\n",
    "\n",
    "X_num_test = X_test[numeric_features]\n",
    "X_cat_test = X_test[categorical_features]\n",
    "\n",
    "X_num_train_full = X_num_train.copy()\n",
    "X_num_val_full   = X_num_val.copy()\n",
    "X_num_test_full  = X_num_test.copy()\n",
    "\n",
    "X_num_train_full['cat_proba'] = oof_proba\n",
    "X_num_val_full['cat_proba']   = val_proba\n",
    "X_num_test_full['cat_proba']  = test_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a8032",
   "metadata": {},
   "source": [
    "Neural Network with CatBoost Leaf Embeddings\n",
    "- Each tree has about 30-60 leaves 9depending on depth)\n",
    "- We embed each tree's leaf index and then concat them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "2f4a2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CatBoostEmbeddingMLP(nn.Module):\n",
    "    def __init__(self, num_numeric_features, cat_dims, embed_dim,\n",
    "                 num_leaf_features, hidden_dim=256, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        # categorical embeddings\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(cat_dim, embed_dim) for cat_dim in cat_dims\n",
    "        ])\n",
    "        cat_total_dim = len(cat_dims) * embed_dim\n",
    "\n",
    "        # input dim = numeric + cat embed + leaf indices\n",
    "        input_dim = num_numeric_features + cat_total_dim + num_leaf_features\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.35),     # <<< ADD DROPOUT HERE\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),     # <<< ADD DROPOUT HERE\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_num, x_cat, leaf_idx):\n",
    "        cat_embeds = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        cat_embeds = torch.cat(cat_embeds, dim=1)\n",
    "\n",
    "        x = torch.cat([x_num, cat_embeds, leaf_idx], dim=1)\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3eac2a",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2837c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "train_dataset = PlayDataset(X_num_train_full, X_cat_train, train_leaves, y_train)\n",
    "val_dataset   = PlayDataset(X_num_val_full, X_cat_val, val_leaves, y_val)\n",
    "test_dataset  = PlayDataset(X_num_test_full, X_cat_test, test_leaves, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=256)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=1024)\n",
    "\n",
    "num_numeric_features = X_num_train_full.shape[1] \n",
    "\n",
    "model = CatBoostEmbeddingMLP(\n",
    "    num_numeric_features=num_numeric_features,\n",
    "    cat_dims=cat_cardinalities,      # list of cardinalities for each categorical column\n",
    "    embed_dim=8,                     # categorical embedding dimension\n",
    "    num_leaf_features=n_trees, \n",
    "    hidden_dim=256,\n",
    "    dropout=0.2                      \n",
    ")\n",
    "\n",
    "# exclude embedding layers from weight decay\n",
    "emb_params = []\n",
    "other_params = []\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"embeddings\" in name:\n",
    "        emb_params.append(param)\n",
    "    else:\n",
    "        other_params.append(param)\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": other_params, \"weight_decay\": 1e-4},\n",
    "    {\"params\": emb_params, \"weight_decay\": 0.0}\n",
    "], lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "0e5063cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_numeric_features = 15\n",
      "num_categorical_features = 5\n",
      "n_trees = 1007\n",
      "n_leaf_values = 64\n",
      "leaf_idx dimension = (223067, 1007)\n"
     ]
    }
   ],
   "source": [
    "print(\"num_numeric_features =\", X_num_train_full.shape[1])\n",
    "print(\"num_categorical_features =\", len(cat_cardinalities))\n",
    "print(\"n_trees =\", cat_model_full.tree_count_)\n",
    "print(\"n_leaf_values =\", n_leaf_values)\n",
    "print(\"leaf_idx dimension =\", train_leaves.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7809aa6d",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "1de783a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete\n",
      "Epoch 2 complete\n",
      "Epoch 3 complete\n",
      "Epoch 4 complete\n",
      "Epoch 5 complete\n",
      "Epoch 6 complete\n",
      "Epoch 7 complete\n",
      "Epoch 8 complete\n",
      "Epoch 9 complete\n",
      "Epoch 10 complete\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for x_num, x_cat, leaf_idx, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x_num, x_cat, leaf_idx).squeeze()\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027717ee",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "de27ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_num, x_cat, leaf_idx, _ in test_loader:\n",
    "        logits = model(x_num, x_cat, leaf_idx).squeeze()\n",
    "        probs = torch.sigmoid(logits)\n",
    "        all_preds.append(probs.cpu().numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "test_labels = (all_preds >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c71c044",
   "metadata": {},
   "source": [
    "Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "86522764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.717035208468442\n",
      "AUC: 0.7811817449025499\n",
      "\n",
      "Confusion Matrix:\n",
      " [[14782  5094]\n",
      " [ 8432 19493]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.69     19876\n",
      "           1       0.79      0.70      0.74     27925\n",
      "\n",
      "    accuracy                           0.72     47801\n",
      "   macro avg       0.71      0.72      0.71     47801\n",
      "weighted avg       0.73      0.72      0.72     47801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluate model ---\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "# Convert y_test (Pandas Series → numpy array)\n",
    "y_test_np = y_test.values\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_test_np, test_labels)\n",
    "\n",
    "# AUC (needs probabilities, not labels)\n",
    "auc = roc_auc_score(y_test_np, all_preds)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_np, test_labels)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_test_np, test_labels)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"AUC:\", auc)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
