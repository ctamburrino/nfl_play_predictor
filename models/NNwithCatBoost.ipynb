{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "514ca125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.8'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "import catboost\n",
    "catboost.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d677874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play_id</th>\n",
       "      <th>yardline_100</th>\n",
       "      <th>qtr</th>\n",
       "      <th>down</th>\n",
       "      <th>ydstogo</th>\n",
       "      <th>goal_to_go</th>\n",
       "      <th>score_differential</th>\n",
       "      <th>drive</th>\n",
       "      <th>posteam_timeouts_remaining</th>\n",
       "      <th>defteam_timeouts_remaining</th>\n",
       "      <th>...</th>\n",
       "      <th>side_of_field_OAK</th>\n",
       "      <th>side_of_field_PHI</th>\n",
       "      <th>side_of_field_PIT</th>\n",
       "      <th>side_of_field_SD</th>\n",
       "      <th>side_of_field_SEA</th>\n",
       "      <th>side_of_field_SF</th>\n",
       "      <th>side_of_field_STL</th>\n",
       "      <th>side_of_field_TB</th>\n",
       "      <th>side_of_field_TEN</th>\n",
       "      <th>side_of_field_WAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   play_id  yardline_100  qtr  down  ydstogo  goal_to_go  score_differential  \\\n",
       "0       68          58.0    1   1.0       10         0.0                 0.0   \n",
       "1       92          53.0    1   2.0        5         0.0                 0.0   \n",
       "2      113          56.0    1   3.0        8         0.0                 0.0   \n",
       "3      162          98.0    1   1.0       10         0.0                 0.0   \n",
       "4      183          98.0    1   2.0       10         0.0                 0.0   \n",
       "\n",
       "   drive  posteam_timeouts_remaining  defteam_timeouts_remaining  ...  \\\n",
       "0      1                         3.0                         3.0  ...   \n",
       "1      1                         3.0                         3.0  ...   \n",
       "2      1                         3.0                         3.0  ...   \n",
       "3      2                         3.0                         3.0  ...   \n",
       "4      2                         3.0                         3.0  ...   \n",
       "\n",
       "   side_of_field_OAK  side_of_field_PHI  side_of_field_PIT  side_of_field_SD  \\\n",
       "0              False              False               True             False   \n",
       "1              False              False               True             False   \n",
       "2              False              False               True             False   \n",
       "3              False              False              False             False   \n",
       "4              False              False              False             False   \n",
       "\n",
       "   side_of_field_SEA  side_of_field_SF  side_of_field_STL  side_of_field_TB  \\\n",
       "0              False             False              False             False   \n",
       "1              False             False              False             False   \n",
       "2              False             False              False             False   \n",
       "3              False             False              False             False   \n",
       "4              False             False              False             False   \n",
       "\n",
       "   side_of_field_TEN  side_of_field_WAS  \n",
       "0              False              False  \n",
       "1              False              False  \n",
       "2              False              False  \n",
       "3               True              False  \n",
       "4               True              False  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/nfl_encoded_v1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "671ea0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (318668, 120)\n",
      "Target shape: (318668,)\n",
      "Categorical features: []\n"
     ]
    }
   ],
   "source": [
    "if \"play_id\" in df.columns:\n",
    "    df = df.drop(columns=[\"play_id\"])\n",
    "\n",
    "X = df.drop(columns=[\"play_type\"])\n",
    "y = df[\"play_type\"]\n",
    "\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "print(\"Feature shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "print(\"Categorical features:\", categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70c22964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (223067, 120)\n",
      "Validation shape: (47800, 120)\n",
      "Testing shape: (47801, 120)\n"
     ]
    }
   ],
   "source": [
    "#First split: train (70%) and temp (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "#Second split: validation (15%) and test (15%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Training shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n",
    "print(\"Testing shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2dca19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: []\n",
      "Categorical feature indices: []\n"
     ]
    }
   ],
   "source": [
    "cat_feature_indices = [X.columns.get_loc(col) for col in categorical_features]\n",
    "\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"Categorical feature indices:\", cat_feature_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78d57035",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = CatBoostClassifier(\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    depth=6,\n",
    "    learning_rate=0.1,\n",
    "    iterations=500,\n",
    "    od_type='Iter',\n",
    "    od_wait=50,\n",
    "    random_seed=42,\n",
    "    verbose=100 #prints training progress every 100 iterations\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2490e664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7757842\tbest: 0.7757842 (0)\ttotal: 34.5ms\tremaining: 17.2s\n",
      "100:\ttest: 0.8026231\tbest: 0.8026231 (100)\ttotal: 2.74s\tremaining: 10.8s\n",
      "200:\ttest: 0.8065102\tbest: 0.8065124 (198)\ttotal: 5s\tremaining: 7.44s\n",
      "300:\ttest: 0.8078534\tbest: 0.8078565 (299)\ttotal: 7.2s\tremaining: 4.76s\n",
      "400:\ttest: 0.8086672\tbest: 0.8086672 (400)\ttotal: 9.4s\tremaining: 2.32s\n",
      "499:\ttest: 0.8088268\tbest: 0.8088478 (491)\ttotal: 12.3s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8088478471\n",
      "bestIteration = 491\n",
      "\n",
      "Shrink model to first 492 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x202daa780d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model.fit(\n",
    "    X_train, y_train, cat_features=cat_feature_indices,\n",
    "    eval_set=(X_val, y_val), use_best_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d32cb44",
   "metadata": {},
   "source": [
    "Extract CatBoost Leaf Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0610429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaf indices for each sample\n",
    "train_leaves = cat_model.calc_leaf_indexes(catboost.Pool(X_train, cat_features=cat_feature_indices))\n",
    "val_leaves   = cat_model.calc_leaf_indexes(catboost.Pool(X_val,   cat_features=cat_feature_indices))\n",
    "test_leaves  = cat_model.calc_leaf_indexes(catboost.Pool(X_test,  cat_features=cat_feature_indices))\n",
    "\n",
    "\n",
    "n_trees = train_leaves.shape[1]\n",
    "n_leaf_values = train_leaves.max() + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172283f3",
   "metadata": {},
   "source": [
    "Convert leaves into embeddings in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "226771a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class PlayDataset(Dataset):\n",
    "    def __init__(self, X_numeric, leaf_indices, y):\n",
    "        # Convert DataFrame to float32 numpy array\n",
    "        self.X_numeric = torch.tensor(X_numeric.values.astype(np.float32))\n",
    "        self.leaf_indices = torch.tensor(leaf_indices.astype(np.int64))\n",
    "        self.y = torch.tensor(y.values.astype(np.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_numeric[idx], self.leaf_indices[idx], self.y[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a8032",
   "metadata": {},
   "source": [
    "Neural Network with CatBoost Leaf Embeddings\n",
    "- Each tree has about 30-60 leaves 9depending on depth)\n",
    "- We embed each tree's leaf index and then concat them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f4a2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CatBoostEmbeddingMLP(nn.Module):\n",
    "    def __init__(self, n_numeric_features, n_trees, n_leaf_values, embed_dim=8):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding layer: (total possible leaf ids → dense vectors)\n",
    "        self.leaf_emb = nn.Embedding(n_leaf_values, embed_dim)\n",
    "\n",
    "        # MLP input size = numeric features + (trees × embed_dim)\n",
    "        mlp_input_dim = n_numeric_features + n_trees * embed_dim\n",
    "\n",
    "        self.fc1 = nn.Linear(mlp_input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x_num, leaf_idx):\n",
    "        # leaf_idx shape: (batch_size, n_trees)\n",
    "        leaf_vectors = self.leaf_emb(leaf_idx)          # (batch, n_trees, embed_dim)\n",
    "        leaf_vectors = leaf_vectors.view(leaf_vectors.size(0), -1)\n",
    "\n",
    "        x = torch.cat([x_num, leaf_vectors], dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.fc3(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3eac2a",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2837c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "train_dataset = PlayDataset(X_train, train_leaves, y_train)\n",
    "val_dataset   = PlayDataset(X_val, val_leaves, y_val)\n",
    "test_dataset = PlayDataset(X_test, test_leaves, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=256)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "model = CatBoostEmbeddingMLP(\n",
    "    n_numeric_features=X_train.shape[1],\n",
    "    n_trees=n_trees,\n",
    "    n_leaf_values=n_leaf_values,\n",
    "    embed_dim=8\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7809aa6d",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1de783a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete\n",
      "Epoch 2 complete\n",
      "Epoch 3 complete\n",
      "Epoch 4 complete\n",
      "Epoch 5 complete\n",
      "Epoch 6 complete\n",
      "Epoch 7 complete\n",
      "Epoch 8 complete\n",
      "Epoch 9 complete\n",
      "Epoch 10 complete\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for x_num, leaf_idx, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x_num, leaf_idx).squeeze()\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027717ee",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de27ba03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48080644 0.43507108 0.44353333 0.46506396 0.18660279 0.9780633\n",
      " 0.98092204 0.43333912 0.9795593  0.98371774]\n",
      "[0 0 0 0 0 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_num, leaf_idx, _ in test_loader:\n",
    "        pred = model(x_num, leaf_idx).squeeze()\n",
    "        all_preds.append(pred.cpu().numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "\n",
    "# 4. Convert to class labels\n",
    "test_labels = (all_preds >= 0.5).astype(int)\n",
    "\n",
    "print(all_preds[:10])   # probabilities\n",
    "print(test_labels[:10]) # 0/1 labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c71c044",
   "metadata": {},
   "source": [
    "Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86522764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5147172653291772\n",
      "AUC: 0.4842270465426377\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 9815 10061]\n",
      " [13136 14789]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.49      0.46     19876\n",
      "           1       0.60      0.53      0.56     27925\n",
      "\n",
      "    accuracy                           0.51     47801\n",
      "   macro avg       0.51      0.51      0.51     47801\n",
      "weighted avg       0.53      0.51      0.52     47801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluate model ---\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "# Convert y_test (Pandas Series → numpy array)\n",
    "y_test_np = y_test.values\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_test_np, test_labels)\n",
    "\n",
    "# AUC (needs probabilities, not labels)\n",
    "auc = roc_auc_score(y_test_np, all_preds)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_np, test_labels)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_test_np, test_labels)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"AUC:\", auc)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
